`bart-szn-2` - training - bart - AdamW - novy tokenizer - Kubova data (24. checkpoint)
`bart-szn-2-backup` - ulozeny 10. checkpoint

`bart-szn-3-params` - data 2017 - pipeline - puvodni introduce_errors - parametry pro kažení dat z Kubovo práce (16. checkpoint)
`bart-szn-3-params-copy` - ulozeny 10. checkpoint

(`bart-szn-3-new-errors` - data 2017 - pipeline - novy introduce_errors - parametry pro kažení dat z Kubovo práce)

---

- jeste chvili spustit `bart-szn-3-params` - mit starsi checkpoint -> Mam 25. checkpoint -> chci cca 40. nebo nejlepsi
  - `bart-szn-3-params`
  - `bart-szn-6-pipeline-finetuning-lr-10-old-data` - finetuning


- zkusit použít moje syntetická data při pretrainingu (mix s akcesem 1:2)
  - generuji

- zkusit nechat jeste bezet pipelinu pretrainingu (treba az z 40. checkpointu), a pak finetuning - (najit nejlepsi checkpoint mezi 26. a 40.)
  - bohuzel mam ckpt, ale tam neni optimizer

- upravit rejection sampling - pridat random (takhle je to moc pravidelne)
    - dopsat do syntetickeho tvoreni

- nastroj na pretagovani - akcesových dat
  - No

- spustit evaluaci na geccc (separe pro jednotlivé domény) - micro/macro f1 score
  - No

- generování chyb - greedy search, zakázat mu jednou za čas nejpravděpodobnější token (bude složitější) - bad_words, diversity_penalty
  - No

---
Mít uložený checkpoint na evaluace nestačí(chce to backup, protože má v sobě i optimizer)