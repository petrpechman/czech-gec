`bart-szn-2` - training - bart - AdamW - novy tokenizer - Kubova data (24. checkpoint)
`bart-szn-2-backup` - ulozeny 10. checkpoint

`bart-szn-3-params` - data 2017 - pipeline - puvodni introduce_errors - parametry pro kažení dat z Kubovo práce (16. checkpoint)
`bart-szn-3-params-copy` - ulozeny 10. checkpoint

(`bart-szn-3-new-errors` - data 2017 - pipeline - novy introduce_errors - parametry pro kažení dat z Kubovo práce)

---

- jeste chvili spustit `bart-szn-3-params` - mit starsi checkpoint -> Mam 49. checkpoint
  - `bart-szn-3-params`
- finetuning:
  - 33. checkpoint -> `bart-szn-6-pipeline-finetuning-lr-10-old-data`
  - 39. checkpoint -> `bart-szn-6-pipe-fine-lr-10-new-data`
  - 41. checkpoint -> `bart-szn-6-pipe-fine-lr-10-new-big-data`
  - zkusit spustit vsechny tri z jednoho checkpointu

- zkusit použít moje syntetická data při pretrainingu (mix s akcesem 1:2)
  - mám vygenerovaná data `code/data/akces-gec/train/new_shuffled_15M.tsv`
  - mám vygenerovaná data `code/data/generized_data/` - cca. 150M rows

- zkusit nechat jeste bezet pipelinu pretrainingu, a pak finetuning (nejlepsi checkpoint mezi 26. a 40.)
  - pouzivam posledni, protoze jsem neukladal optimizer -> pouzivam posledni

- upravit rejection sampling - pridat random (takhle je to moc pravidelne) a dopsat do syntetickeho tvoreni
  - opraveno -> pouzit v pipeline
  - opraven bug: 158 new_char = current_char + ' ' + np.random.choice(char_vocabulary)
  - `bart-szn-7-pretrain` - jen me/mne (`bart-szn-7-pretrain-copy`)
  - cele to zrychlit !!!

- spustit evaluaci na geccc (separe pro jednotlivé domény) - micro/macro f1 score
  - na celem GECCC -> micro F1-score

- generování chyb - greedy search, zakázat mu jednou za čas nejpravděpodobnější token (bude složitější) - bad_words, diversity_penalty
  - `bart-szn-5-generate-errors`

- nastroj na pretagovani - akcesových dat
  - No

- debug multi GPU
  - No

---

Moje:

with open("natives-web-informal-test.txt", "w") as f:
     for i in range(len(meta_sentence)):
             if part[meta_sentence[i]] == "Natives Web Informal":
                     lines = m2_text[i].split("\t")
                     lines = [line+"\n" for line in lines]
                     f.writelines(lines)



Pr = TP / (TP + FP)
Re = TP / (TP + FN) = TP / P

total_stat_correct ~ TP
total_stat_proposed ~ (TP + FP)
total_stat_gold ~ (TP + FN)