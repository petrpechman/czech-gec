pretrain:
- zachovat kazdy 10. checkpoint
- `bart-szn-10-pretrain-aspell` - zatim 9 epoch (aspon 30)
  - `bart-szn-12-pretrain-aspell`
- `bart-szn-10-pretrain-dist-2-ratio-5-2` - zatim 4 epochy (taky az 50 epoch)
  - `bart-szn-12-pretrain-aspell`
- spustis se specifickými chybami -
  - nejak rozumne pravdepodobnosti (diakritizace, carka, atd.)
  - jen s aspellem
  - `bart-szn-12-pretrain-spec-errs`


finetuning:
- z kazdeho 10. checkpointu (pomer dat - 1:2)
- zkusit ruzne pomery mezi akcesem a syntetickými daty - 1:2, 1:0 (jen akces - male epochy), 1:5, (1:10)
- klidně zmenšit velikost epoch (jeste jednou rozctvrtit)


Přetagovat data:
- akces-gec
  - ohlidat new lines (3 a vic za 2)
  - dostat m2 file - https://github.com/ufal/errant_czech/blob/czech/errant/commands/m2_to_m2.py 
  - retagovat ziskany m2 file (dat do evaluace)
- pridat retag v evaluaci


Dodelat datasety:
- vzit cisty geccc - plain text(dev, test) a dodelat tam specificke chyby - 100x, 200x a 500x(jestli to vubec jde) kazdou (vejit se do 30_000)(rejection sampling) 
- vzit m2 soubor (už s chybami v gecccu, proto m2) a do nej pridelat dalsi typicke chyby - udelat navic cca. 100 dalsich


Technické:
- zlepsit evaluaci aby bezela paralalne pro rozdeleni data jak akces, tak gec
- tip: multi-gpu - zkusit zmenšit batch_size

Evaluace:
- zkusit evaluaci na nově vytvořených datasetech

---
annotator.py - 104 - edit = self.classify(edit, orig, cor) # PETR EDIT
---
akces-get 
- train.tsv: 42210 lines
- ratio 0:1 - epocha 2048 -> 20.6 epoch
- ratio 2:1 - epocha 7375 -> 17.17 epoch
- ratio 5:1 - epocha 7375 -> 34.34 epoch
- ratio 10:1 - epocha 7375 -> 63 epoch

petr-bart-train-13-pretrain-aspell-s-17-r-0-1-fine-65dbd7dlvmg6   1/1     Running   0          3d
petr-bart-train-13-pretrain-aspell-s-17-r-10-1-fine-99c4f65tznj   1/1     Running   0          3d
petr-bart-train-13-pretrain-aspell-s-17-r-2-1-fine-774bb486h6pk   1/1     Running   0          3d
petr-bart-train-13-pretrain-aspell-s-17-r-5-1-fine-5577885j5h57   1/1     Running   0          3

k cp sleep-pod-5bf578fd5b-pxw2v:/pechmanp/czech-gec/code/src/bart-szn-13-pretrain-aspell-s-17-r-0-1-fine/tmp/checkpoint/results-dev ./tmp/checkpoint/results-dev



def create_m2(annotator, source_sentence, predicted_sentence):
    orig = source_sentence
    cor = predicted_sentence
    cor_id = 0
    lev = False
    merge = "all-split"
    orig = annotator.parse(orig)
    output = " ".join(["S"] + [token.text for token in orig]) + "\n"
    cor = cor.strip()
    if orig.text.strip() == cor:
        output = output + noop_edit(cor_id) + "\n"
    else:
        cor = annotator.parse(cor)
        edits = annotator.annotate(orig, cor, lev, merge)
        for edit in edits:
            output = output + edit.to_m2(cor_id) + "\n"
    return output.strip()


ErrorMeMne
0.54    pos_err: 26      num_errors: 14      total_tokens: 27766   0.00094

---
Counts:
ErrorMeMne
0.5     104     52      128014  0.00081
ErrorMeMneSuffix
0.5     28      14      128014  0.00022
ErrorMeMneIn
0.47    268     125     128014  0.00209
ErrorSuffixIY
0.51    3457    1766    128014  0.027
ErrorDNT
0.5     2871    1426    128014  0.02243
ErrorEnumeratedWord
0.49    4296    2122    128014  0.03356
ErrorUU
0.46    614     283     128014  0.0048
ErrorCondional
0.51    243     125     128014  0.0019
ErrorSpecificWords
0.0     0       0       128014  0.0
ErrorSZPrefix
0.5     2442    1211    128014  0.01908
ErrorNumerals
0.5     4       2       128014  3e-05
ErrorMyMi
0.49    107     52      128014  0.00084
ErrorBeBjeSuffix
0.56    16      9       128014  0.00012
ErrorBeBjeIn
0.57    70      40      128014  0.00055
ErrorSebou
0.67    6       4       128014  5e-05
ErrorSentenceFirstUpper
0.05    2948    145     128014  0.02303
ErrorSentenceFirstLower
0.54    112     61      128014  0.00087
ErrorTitleToLower
0.52    2634    1367    128014  0.02058
ErrorLowerToTitle
0.09    28314   2504    128014  0.22118
ErrorPrepositionSZ
0.52    1159    603     128014  0.00905
ErrorCommaAdd
0.04    119605  5087    128014  0.93431
ErrorCommaRemove
0.67    3       2       128014  2e-05
ErrorRemoveDiacritics
0.1     13364   1303    128014  0.10439
ErrorAddDiacritics
0.05    31919   1622    128014  0.24934


{
    "MeMne": [0.063, 0.0, false],
    "MeMneSuffix": [0.063, 0.0, false],
    "MeMneIn": [0.063, 0.0, false],
    "SuffixIY": [0.063, 0.0, false],
    "DTN": [0.063, 0.0, false],
    "EnumeratedWord": [0.063, 0.0, false],
    "UU": [0.063, 0.0, false],
    "Conditional": [0.063, 0.0, false],
    "SpecificWords": [0.063, 0.0, false],
    "SZPrefix": [0.063, 0.0, false],
    "Numerals": [0.063, 0.0, false],
    "MyMi": [0.063, 0.0, false],
    "BeBjeSuffix": [0.063, 0.0, false],
    "BeBjeIn": [0.063, 0.0, false],
    "Sebou": [0.063, 0.0, false],
    "SentenceFirstUpper": [0.063, 0.0, false],
    "SentenceFirstLower": [0.063, 0.0, false],
    "TitleToLower": [0.063, 0.0, false],
    "LowerToTitle": [0.063, 0.0, false],
    "PrepositionSZ": [0.063, 0.0, false],
    "CommaAdd": [0.063, 0.0, false],
    "CommaRemove": [0.063, 0.0, false],
    "RemoveDiacritics": [0.063, 0.0, false],
    "AddDiacritics": [0.063, 0.0, false]
}