- do errant - vyhodnoceni na chybach pridat pocty chyb, ktere jsou ulozene ve filu

- upravit evaluaci (vylepšit)
  - setřidit věty, aby šly od největší
  - paralelně přes věty
  - pool.imap async

- pretrainingy
  - vzit pro každý experiment všechny jeho checkpointy a vyhodnotit na gecccu (m2scorer)
    - jak minule vysledky, tak i nove

- finetuning na gecccovych datech (0:1)
  - z posledních epoch (udelat i pro akces)
  - evaluace na gecccu i na rozpadlém gecccu (zkusit jen s jednou predikcí, nedělat dvakrát) (m2scorer)

- experimetny:
  - mt5-base (mt5-large) - mt5-large (1 GPU -> batch_size=3, 2 GPU -> nefunguje)
  - vetsi model:
    - zkusit rozbehnout multi GPU - done
    - large bart - create_model config_big - done

- ! opravit si rejection sampling ! - nepouzivat num_errors
  - v mailu pdf
  - tvarit se, ze vim kolik slotu mi jeste zbyva

- dodelat datasety:
  - vybirat nahodne z anotatoru pro vytvoreni umeleho datasetu (zamyslet se, jeslti by slo s vice anotatory)
  - vzit cisty geccc - plain text(dev, test) a dodelat tam specificke chyby - 100x, (200x a 500x) (jestli to vubec jde) kazdou (vejit se do 30_000)(rejection sampling) - pro evaluaci
  - vzit m2 soubor(dev, test, train) (už s chybami v gecccu, proto m2) a do nej pridelat dalsi typicke chyby - udelat navic cca. 100 dalsich (200, 500) - evaluace i finetuning 
    - to do: separátní soubory nebo cely? nejspis cely

- zapsat si proc je pomer 0:1 nejlepsi

- priste zoom - asi ctvrtek - asi dopo - ja napisu v ctvrtek nebo patek

---

    "m2_data_dev": ["../../data/akces-gec/dev/dev.all.m2", ["m2_scorer"]],
    "m2_data_test": ["../../data/akces-gec/test/test.all.m2", ["m2_scorer"]],

    "dev_geccc_datasets": [
        ["../../data/geccc-split/data/dev-splits/natives-formal-dev.m2", ["m2_scorer"]],
        ["../../data/geccc-split/data/dev-splits/romani-dev.m2", ["m2_scorer"]],
        ["../../data/geccc-split/data/dev-splits/natives-web-informal-dev.m2", ["m2_scorer"]],
        ["../../data/geccc-split/data/dev-splits/second-learners-dev.m2", ["m2_scorer"]]
    ],

    "test_geccc_datasets": [
        ["../../data/geccc-split/data/test-splits/natives-formal-test.m2", ["m2_scorer"]],
        ["../../data/geccc-split/data/test-splits/romani-test.m2", ["m2_scorer"]],
        ["../../data/geccc-split/data/test-splits/natives-web-informal-test.m2", ["m2_scorer"]],
        ["../../data/geccc-split/data/test-splits/second-learners-test.m2", ["m2_scorer"]]
    ],
    
    "retag_dev_geccc_datasets": [
        ["../../data/geccc-split-retag/dev/natives-formal-dev-retag.m2", ["errant"]],
        ["../../data/geccc-split-retag/dev/romani-dev-retag.m2", ["errant"]],
        ["../../data/geccc-split-retag/dev/natives-web-informal-dev-retag.m2", ["errant"]],
        ["../../data/geccc-split-retag/dev/second-learners-dev-retag.m2", ["errant"]]
    ],

    "retag_test_geccc_datasets": [
        ["../../data/geccc-split-retag/test/natives-formal-test-retag.m2", ["errant"]],
        ["../../data/geccc-split-retag/test/romani-test-retag.m2", ["errant"]],
        ["../../data/geccc-split-retag/test/natives-web-informal-test-retag.m2", ["errant"]],
        ["../../data/geccc-split-retag/test/second-learners-test-retag.m2", ["errant"]]
    ],

    "other_datasets": [
        ["../../data/akces-gec-retag/dev/dev-retag.all.m2", ["errant"]],
        ["../../data/akces-gec-retag/test/test-retag.all.m2", ["errant"]]
    ],


tensorboard --load_fast false --logdir . --samples_per_plugin text=1000

---


Counts:
ErrorMeMne
0.46    818     375     749257  0.00109
ErrorMeMneSuffix
0.2     267     54      749257  0.00036
ErrorMeMneIn
0.26    1321    343     749257  0.00176
ErrorSuffixIY
0.01    17617   206     749257  0.02351
ErrorDNT
0.0     10804   0       749257  0.01442
ErrorEnumeratedWord
0.17    20918   3564    749257  0.02792
ErrorUU
0.0     2010    0       749257  0.00268
ErrorCondional
0.0     915     0       749257  0.00122
ErrorSpecificWords
0.0     2       0       749257  0.0
ErrorSZPrefix
0.03    9407    302     749257  0.01256
ErrorNumerals
0.5     22      11      749257  3e-05
ErrorMyMi
0.25    565     139     749257  0.00075
ErrorBeBjeSuffix
0.05    84      4       749257  0.00011
ErrorBeBjeIn
0.16    254     41      749257  0.00034
ErrorSebou
0.0     21      0       749257  3e-05
ErrorSentenceFirstUpper
0.14    18317   2494    749257  0.02445
ErrorSentenceFirstLower
0.05    1658    80      749257  0.00221
ErrorTitleToLower
0.31    8112    2514    749257  0.01083
ErrorLowerToTitle
0.01    117672  1490    749257  0.15705
ErrorPrepositionSZ
0.05    4695    215     749257  0.00627
ErrorCommaAdd
0.0     435229  0       749257  0.58088
ErrorCommaRemove
0.35    49879   17376   749257  0.06657
ErrorRemoveDiacritics
0.26    65305   17132   749257  0.08716
ErrorAddDiacritics
0.11    148283  16374   749257  0.19791